# Machine Learning

目前计划：

**课程方面** 周一、三、五学习MIT的线性代数，周二、四、六学习Berkeley的算法课

**书本方面** 周一、三、五学习图像处理，周二、四、六学习西瓜书，周三、周六学习统计学习方法  [GitHub链接](https://github.com/fengdu78/lihang-code) 

周日完成西瓜书后面的习题，适当完成统计学习方法的代码，查漏补缺并整理报告

每天至少三小时，尽量达到四小时以上，少的时间要尽快补上
		
		
## 2019.11.5 fixed
###  图像处理部分：
##### 整体进度从3.5学习到了第四章结束。

3.5各向异性扩散涉及到热方程的并没有理解，先mark一下

了解了各种算子的特征（优点以及缺点），**平均算了可以去除大量噪声，但是使特征边界模糊;高斯平均保留更多特征，但与直接求平均相比，几乎没有优势(噪声不是高斯分布的);中值算子保留些噪声，但得到清晰的边界特征;截断中值算子去除更多噪声，但也去除更多图像细节。很显然，由图3.24(b)和图3.24(c)的结果表明，加大截断中值模板可以提高性能。这是预料之中的，由于通过加大截断中值模板，实质上可以加大分布，从中找出模式。**

第四章讲的是低层次特征提取以及边缘检测。最基本的是差分+均匀阈值方法。并且学习了分块阈值方法, 以便每个块的光照都近似均匀的 。[学习链接]( https://blog.csdn.net/kk55guang2/article/details/78475414 ).

接着从数学角度（泰勒展开）理解了边缘检测算子。并学习了更多的边缘检测算子，如Prewitt,  Sobel(帕斯卡三角形), 并从频域角度理解了Sobel算子，复习了z变换。接着学习了Canny算子和滞后阈值。

二阶算子：包括拉普拉斯算子，Marr-Hildreth(高斯算子与图像进行卷积后进行二阶微分，同时包含微分和平滑，这个算子与人类视觉密切关系，具有多分辨率分析能力)。

比较了各种 边缘检测算子： **中值滤波常用于一般性（非超声波）的程序处理，作为*预滤波器*用于一阶和二阶方法效果显著；所有边缘算子的结果都是用滞后阈值处理来实现的，其中，为了更好地反映其性能，这些阈值都是手动选择的。Prewitt 和Sobel 算子显示了一些边界,但处理后的图像中仍然保留了许多噪声（Sobel少一点）；Laplacian 算子对于大噪声的图片几乎没有留下什么信息；Mar- Hildreth方法的处理结果有了一些改善，对于如此大噪声的图像，很难选择个大小适当的LoG算子来检测如此多维的特征，在噪声过滤所需的算子大小与目标特征的大小之间需要折中；Canny 和Spacek算子的处理效果非常好。**

为了进一步学习相位一致性，学习了小波变换，了解了傅立叶变换的弱点以及小波变换的优势。[学习链接](https://www.cnblogs.com/jfdwd/p/9249850.html).

![小波变换](https://img-blog.csdn.net/20160705113512598)

做傅里叶变换只能得到一个频谱，做小波变换却可以得到一个时频谱！

为了学习通过亮度变化计算曲率，学习了图像梯度。[学习链接](https://blog.csdn.net/saltriver/article/details/78987096)



### 机器学习部分：

##### 整体进度从第一章开始一直到第四章第二节结束。

第一章从宏观上把握了机器学习到底是什么，可以用来干什么，发展历史，目前发展到了什么地步，大概是怎么样的一个操作流程。学习了一些机器学习方面的专有名词。根据训练数据是否有标记信息，学习任务大致可以划分为两大类：**监督学习和无监督学习**，**分类和回归**是前者的代表，**聚类**是后者的代表。了解了泛化性、假设空间、归纳偏好等等概念。

第二章开始我觉觉得稍微有点硬核了，数学表达式多了起来，用到了很多以前微积分、概率论、线性代数中的知识，我也因此决定要认认真真补一补数学的基础，包括MIT的线性代数以及统计学习方法。这一章学习了如何评估自己的学习器。我们希望得到泛化误差小的学习器。**然而我们无法直接比较泛化误差**，因此有了这一章的许许多多的评估方法。最基本的是留出法，即按一定比例留出一部分样本当测试集，用测试集来评估误差，作为对泛化误差的估计。接着学习了更加高级有效的交叉验证以及交叉验证的特例，留一法，并编写代码验证了这两种验证的方法。**当数据量不太够的时候**，我们也可以使用自助法。

